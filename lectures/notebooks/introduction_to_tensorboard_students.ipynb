{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFoT71fTySwXqa2eYr3kzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIA-Oceanix/DLOA2023/blob/main/lectures/notebooks/introduction_to_tensorboard_students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to TensorBoard\n",
        "\n",
        "[TensorBoard](https://www.tensorflow.org/tensorboard) is an interactive tool used to visualise your metrics and graphs.\n",
        "\n",
        "In this notebook, we will learn to use the basics of TensorBoard with MNIST dataset as example.\n",
        "\n",
        "\n",
        "## Table of contents\n",
        "\n",
        "1. Data\n",
        "2. Models\n",
        "3. Learning & logging\n",
        "4. Sharing your board\n",
        "\n",
        "A few useful modules:"
      ],
      "metadata": {
        "id": "1JSc2Vk2nZOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmwuc4ccm9nv"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint  # pretty print\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And some global parameters:"
      ],
      "metadata": {
        "id": "2r6n0ELG6t9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_epochs = 5\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f'Currently using {device}.')"
      ],
      "metadata": {
        "id": "JauBoluU6woG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data\n",
        "\n",
        "Define the MNIST train and test datasets:"
      ],
      "metadata": {
        "id": "rx7_QSPPsacg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root='./data/',  # Root directory where the dataset is stored\n",
        "    train=True,\n",
        "    transform=ToTensor(),  # Turn the data into tensor\n",
        "    download=True,  # Download the dataset if necessary\n",
        ")"
      ],
      "metadata": {
        "id": "jQ7KItTCsmUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(\n",
        "    root='./data/',\n",
        "    train=False,\n",
        "    transform=ToTensor(),\n",
        "    download=True,\n",
        ")"
      ],
      "metadata": {
        "id": "u_dLdzbsuGmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some details about the dataset\n",
        "print(f'    Number of classes: {len(train_data.classes)}')\n",
        "print(f'      Data dimensions: {train_data.data[0].shape}')\n",
        "print(f'Size of the train set: {len(train_data)}')\n",
        "print(f' Size of the test set: {len(test_data)}\\n')\n",
        "\n",
        "print('Classes\\n-------')\n",
        "pprint(train_data.classes)"
      ],
      "metadata": {
        "id": "TGdoJziovB3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample\n",
        "plt.imshow(train_data.data[0])"
      ],
      "metadata": {
        "id": "LO1qX5PnvNdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train data into train and validation data\n",
        "_train, _validation = torch.utils.data.random_split(train_data, [.8, .2])"
      ],
      "metadata": {
        "id": "Gp6GIU0IxsNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(_train, batch_size)\n",
        "validation_loader = torch.utils.data.DataLoader(_validation, batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size)"
      ],
      "metadata": {
        "id": "JChb7uvK6R7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Models\n",
        "\n",
        "We are going to compare two simple models and see how they behave with TensorBoard.\n",
        "\n",
        "The models are:\n",
        "\n",
        "- a simpel **multi-layers perceptron** (`MLP`);\n",
        "- a simple **convolutional network** (`ConvNet`)."
      ],
      "metadata": {
        "id": "hbrPBHPk-eSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(28*28, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.layers(X)"
      ],
      "metadata": {
        "id": "iZo9vsaU-l9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 5, 3, padding=1),\n",
        "            torch.nn.BatchNorm2d(5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(5, 1, 3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            torch.nn.Flatten(start_dim=1),\n",
        "            torch.nn.Linear(28*28, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.layers(X)"
      ],
      "metadata": {
        "id": "RiCa9SNaGJL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Learning & logging\n",
        "\n",
        "Before that, remove eventuel old runs and start and new board.\n",
        "\n",
        "We need first to instanciate a `SummaryWriter` that will keep a track of everything we will log.\n",
        "\n",
        "We will perform a simulation with the ConvNet first."
      ],
      "metadata": {
        "id": "uubJ1MiwSvxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf ./runs/"
      ],
      "metadata": {
        "id": "wtbLmD6FXSI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "aikptDd2XJYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch\n",
        "\n",
        "To add data in TensorBoard, you need an instance of the class [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter). You can specify the location where the data will be stored in the `log_dir` parameter."
      ],
      "metadata": {
        "id": "Lazgvg7lVR7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tb_convnet = SummaryWriter(log_dir='./runs/convnet')"
      ],
      "metadata": {
        "id": "mELntV-j-eHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first learn to add scalars value (`int`, `float`). For example, metrics are scalar values.\n",
        "\n",
        "To add a scalar, you need the method [`SummaryWriter.add_scalar`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar):\n",
        "\n",
        "```python\n",
        "SummaryWriter.add_scalar(tag, value, global_step)\n",
        "```\n",
        "\n",
        "Where:\n",
        "- `tag` is where the scalar will be stored (for example \"Loss\"). You can add several scalar with the same label so we can track the evolution of the scalar throughout the `global_step`. You can specify a path so you can categorise your scalars (for example \"Loss/Training\"). Each `tag` corresponds to **one** graph;\n",
        "- `value` is the scalar you want to save;\n",
        "- (optional) `global_step` is the $n$-th iteration of the scalar (for example, the $n$-th epoch).\n",
        "\n",
        "Let's write the training and testing processes and add some scalars:"
      ],
      "metadata": {
        "id": "y2K4FkBt-knk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, epoch, tb):\n",
        "    n_samples = len(dataloader.dataset)\n",
        "    n_batches = len(dataloader)\n",
        "    model.train()\n",
        "\n",
        "    train_loss, correct = 0, 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        train_loss += loss\n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f'loss: {loss:>7f}  [{current:>5d}/{n_samples:>5d}]')\n",
        "    train_loss /= n_batches\n",
        "    correct /= n_samples\n",
        "\n",
        "    tb.add_scalar('Loss/Train', loss, epoch)  # /!\\\n",
        "    tb.add_scalar('Accuracy/Train', correct, epoch)  # /!\\"
      ],
      "metadata": {
        "id": "Z8wNuT62EDjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def validation(dataloader, model, loss_fn, epoch, tb):\n",
        "    n_samples = len(dataloader.dataset)\n",
        "    n_batches = len(dataloader)\n",
        "    model.eval()\n",
        "\n",
        "    validation_loss, val_correct = 0, 0\n",
        "    for X, y in dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        validation_loss += loss_fn(pred, y).item()\n",
        "        val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    validation_loss /= n_batches\n",
        "    val_correct /= n_samples\n",
        "    print(f'Validation Error:\\nAccuracy: {(100*val_correct):>0.1f}%, Avg loss: {validation_loss:>8f}\\n')"
      ],
      "metadata": {
        "id": "3c-NFdzNZPxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**>>> In the process `validation`, add the loss and accuracy values in TensorBoard.**\n",
        "\n",
        "And a final procedure that handles the training and the test:"
      ],
      "metadata": {
        "id": "TXqfZTRGrTRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model, loss_fn, optimizer, scheduler, tb):\n",
        "    for t in range(n_epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train(train_loader, model, loss_fn, optimizer, t, tb)\n",
        "        validation(validation_loader, model, loss_fn, t, tb)\n",
        "\n",
        "        tb.add_scalar('Learning Rate', scheduler.get_last_lr()[0], t)  # /!\\\n",
        "        scheduler.step()\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "1FaUInisq0Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please be aware that:\n",
        "\n",
        "1. The learning rate is normally a hyperparameter and there is a specific method to track hyperparameter in a way such that we can map metrics to hyperparameter. See [`SummaryWriter.add_hparams`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_hparams) for more details;\n",
        "2. We haven't called `train`, `validation` and `run` yet so no scalar have been added yet to TensorBoard.\n",
        "\n",
        "\n",
        "Let's instanciate the model:"
      ],
      "metadata": {
        "id": "RF4L_cHxaLA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convnet = ConvNet().to(device)\n",
        "convnet"
      ],
      "metadata": {
        "id": "HnVTYd1caMa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is possible to use TensorBoard to show a graph of your model, it can be very useful if your model is complex as it would allow you to visualise it. We use the method [`SummaryWriter.add_graph`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph) for that:\n",
        "\n",
        "```python\n",
        "SummaryWriter.add_graph(model, data)\n",
        "```\n",
        "\n",
        "Where:\n",
        "- `model` is your PyTorch module;\n",
        "- `data` will be used to feed the model so TensorBoard can visualise it.\n",
        "\n",
        "Let's add our ConvNet in TensorBoard:"
      ],
      "metadata": {
        "id": "y_iill7UMVQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample, _ = next(iter(train_loader))\n",
        "tb_convnet.add_graph(convnet, sample)  # /!\\"
      ],
      "metadata": {
        "id": "wkxlAnpyMkOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---> ðŸ‘€ See TensorBoard**\n",
        "\n",
        "Also, you can add images to the board with [SummaryWriter.add_image](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image):\n",
        "\n",
        "```python\n",
        "SummaryWriter.add_image(tag, img, global_step)\n",
        "```\n",
        "Where:\n",
        "- `tag` same as previously;\n",
        "- `img` is a **tensor** (or a **numpy.ndarray**);\n",
        "- (optional) `global_step` same as previously.\n",
        "\n",
        "Let's add a sample of our dataset (a whole batch) in the board:"
      ],
      "metadata": {
        "id": "M9z5i8eW4eu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = torchvision.utils.make_grid(sample)\n",
        "tb_convnet.add_image(\"Batch\", grid, global_step=None)  # /!\\"
      ],
      "metadata": {
        "id": "-BWwRVj04i7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---> ðŸ‘€ See TensorBoard**\n",
        "\n",
        "**>>> Modify the previous cell such that we can see all batches of the training set in TensorBoard**\n",
        "[ Pro tips: loop over `train_loader` with the function `enumerate` ]\n",
        "\n",
        "**---> ðŸ‘€ See TensorBoard**\n",
        "\n",
        "Then we can define the loss function (`loss_fn`), the optimizer and a learning rate scheduler before running an experiment:"
      ],
      "metadata": {
        "id": "MGFUMCs2ROYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(convnet.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "\n",
        "run(\n",
        "    model=convnet,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    tb=tb_convnet,\n",
        ")"
      ],
      "metadata": {
        "id": "drJGidGptZEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---> ðŸ‘€ See TensorBoard**\n",
        "\n",
        "Let's add another model (MLP) to our board in order to compare it with the previous one (ConvNet).\n",
        "\n",
        "**>>> Complete the following cell.**"
      ],
      "metadata": {
        "id": "RXMX3378F1MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciate a new board in `./runs/mlp`\n",
        "tb_mlp = ...  # /!\\\n",
        "\n",
        "# Instanciate the MLP module (and send it to `device`)\n",
        "mlp = ...  # /!\\\n",
        "\n",
        "# Loss function, optimizers & LR scheduler\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(mlp.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "\n",
        "# Complete the following:\n",
        "run(\n",
        "    model=mlp,  # /!\\\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    tb=tb_mlp,  # /!\\\n",
        ")"
      ],
      "metadata": {
        "id": "1AunrnrPF6vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's not forget to close the board:"
      ],
      "metadata": {
        "id": "_ozRSYmKDfxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tb_convnet.close()\n",
        "tb_mlp.close()"
      ],
      "metadata": {
        "id": "TNcYtsCkDfbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Sharing your board\n",
        "\n",
        "You can host your board online in order to share it with other people on [tensorboard.dev](https://tensorboard.dev).\n",
        "\n",
        "**The data stored are public and visible to anyone, do not share sensitive data and results!**"
      ],
      "metadata": {
        "id": "4my7NzTTVI-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard dev upload --logdir runs --name \"my board\" --description \"a test board\""
      ],
      "metadata": {
        "id": "CjM9j4KFVKsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other\n",
        "\n",
        "- [TensorBoard official website](https://www.tensorflow.org/tensorboard);\n",
        "- [Default page on PyTorch about TensorBoard](https://pytorch.org/docs/stable/tensorboard.html);\n",
        "- [How to use TensorBoard with PyTorch](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html);\n",
        "- [A tutorial on TensorBoard with PyTorch](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html);\n",
        "- [Another guide to use TensorBoard](https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3);\n",
        "- [TensorBoard dev](https://tensorboard.dev);"
      ],
      "metadata": {
        "id": "sBKV0dbCE4kd"
      }
    }
  ]
}